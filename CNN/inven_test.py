import cv2
import numpy as np
import pickle
from tensorflow.keras.models import load_model
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input
import os

# --- 1. ì„¤ì • ---
SCREENSHOT_PATH = './CNN/test4.png'
MODEL_PATH = './CNN/sephiria_item_model.keras'
CLASSES_PATH = './CNN/classes.pickle'
IMG_SIZE = 128

BORDER_COLOR_BGR = (52, 32, 36)

os.makedirs('./debug_test_rois', exist_ok=True)
os.makedirs('./debug_test_processed', exist_ok=True)

# --- 2. ì„íŒ í´ë˜ìŠ¤ ---
def load_tablet_classes(tablets_folder='./assets/tablets'):
    tablet_classes = set()
    if os.path.exists(tablets_folder):
        for filename in os.listdir(tablets_folder):
            if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.webp')):
                class_name = os.path.splitext(filename)[0]
                tablet_classes.add(class_name)
    print(f"âœ… ì„íŒ: {len(tablet_classes)}ê°œ")
    return tablet_classes

# --- 3. NMS (ì¤‘ë³µ ì œê±°) ---
def non_max_suppression(boxes, overlap_thresh=0.3):
    if len(boxes) == 0:
        return []
    
    boxes = np.array(boxes)
    pick = []
    
    x1 = boxes[:, 0]
    y1 = boxes[:, 1]
    x2 = boxes[:, 0] + boxes[:, 2]
    y2 = boxes[:, 1] + boxes[:, 3]
    
    area = boxes[:, 2] * boxes[:, 3]
    idxs = np.argsort(y1)
    
    while len(idxs) > 0:
        last = len(idxs) - 1
        i = idxs[last]
        pick.append(i)
        
        xx1 = np.maximum(x1[i], x1[idxs[:last]])
        yy1 = np.maximum(y1[i], y1[idxs[:last]])
        xx2 = np.minimum(x2[i], x2[idxs[:last]])
        yy2 = np.minimum(y2[i], y2[idxs[:last]])
        
        w = np.maximum(0, xx2 - xx1)
        h = np.maximum(0, yy2 - yy1)
        
        overlap = (w * h) / area[idxs[:last]]
        
        idxs = np.delete(idxs, np.concatenate(([last], np.where(overlap > overlap_thresh)[0])))
    
    return boxes[pick].tolist()

# --- 4. ìŠ¬ë¡¯ ì°¾ê¸° (í•˜ì´ë¸Œë¦¬ë“œ: í…Œë‘ë¦¬ + ë°˜ì „ í•©ì²´) ---
# [ìˆ˜ì • 2] ê·¸ë¦¬ë“œ ì¸ì‹ì„ ìœ„í•œ 'í•˜ì´ë¸Œë¦¬ë“œ' ë¡œì§ ì ìš©
def find_inventory_slots(image):
    print("\n=== ìŠ¬ë¡¯ ê²€ìƒ‰ (í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë“œ) ===")
    
    # ê³µí†µ ì„¤ì •: í…Œë‘ë¦¬ ìƒ‰ìƒ ë§ˆìŠ¤í¬ ë§Œë“¤ê¸°
    tolerance = 15
    lower = np.array([max(0, c - tolerance) for c in BORDER_COLOR_BGR])
    upper = np.array([min(255, c + tolerance) for c in BORDER_COLOR_BGR])
    
    # mask: í…Œë‘ë¦¬=255, ë°°ê²½=0
    mask = cv2.inRange(image, lower, upper)
    
    # ë…¸ì´ì¦ˆ ì œê±° (ê³µí†µ)
    kernel = np.ones((3, 3), np.uint8)
    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=1)
    
    candidates = []

    # [ë°©ë²• A] í…Œë‘ë¦¬(Contour) ê¸°ë°˜ ê²€ìƒ‰
    edges = cv2.Canny(mask, 50, 150)
    contours_A, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    count_a = 0
    for cnt in contours_A:
        x, y, w, h = cv2.boundingRect(cnt)
        ar = w / float(h)
        # ì¡°ê±´: 85~130px ì •ì‚¬ê°í˜•
        if 85 < w < 130 and 85 < h < 130 and 0.8 < ar < 1.2:
            candidates.append([x, y, w, h])
            count_a += 1

    # [ë°©ë²• B] ë§ˆìŠ¤í¬ ë°˜ì „(Inversion) ê¸°ë°˜ ê²€ìƒ‰ (ì´ì–´ì ¸ ìˆëŠ” ê·¸ë¦¬ë“œ í•´ê²°ì±…)
    mask_inv = cv2.bitwise_not(mask)
    contours_B, _ = cv2.findContours(mask_inv, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    count_b = 0
    for cnt in contours_B:
        x, y, w, h = cv2.boundingRect(cnt)
        ar = w / float(h)
        if 85 < w < 130 and 85 < h < 130 and 0.8 < ar < 1.2:
            candidates.append([x, y, w, h])
            count_b += 1

    print(f"ğŸ”¹ ë°©ë²• A(í…Œë‘ë¦¬) ë°œê²¬: {count_a}ê°œ")
    print(f"ğŸ”¹ ë°©ë²• B(ë°˜ì „) ë°œê²¬: {count_b}ê°œ")
    
    if len(candidates) == 0:
        print("âš ï¸ ìŠ¬ë¡¯ì„ ëª» ì°¾ì•˜ìŠµë‹ˆë‹¤. BORDER_COLOR_BGRì„ í™•ì¸í•˜ì„¸ìš”.")
        cv2.imwrite('./CNN/debug_mask_border.png', mask) # ë””ë²„ê·¸ìš©
        return []

    # [ë°©ë²• C] ì¤‘ë³µ ì œê±° (NMS)
    final_slots = non_max_suppression(candidates, overlap_thresh=0.3)
    
    if isinstance(final_slots, np.ndarray):
        final_slots = final_slots.tolist()
    
    # ì •ë ¬ (ìƒ -> í•˜, ì¢Œ -> ìš°)
    final_slots = sorted(final_slots, key=lambda s: (s[1] // 20, s[0]))
    
    print(f"âœ… ìµœì¢… ì¤‘ë³µ ì œê±° í›„: {len(final_slots)}ê°œ")

    # ë””ë²„ê·¸ ì‹œê°í™”
    vis = image.copy()
    for i, (x, y, w, h) in enumerate(final_slots):
        cv2.rectangle(vis, (x, y), (x+w, y+h), (0, 255, 0), 2)
        cv2.putText(vis, str(i), (x+5, y+25), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
    
    cv2.imwrite('./CNN/debug_slots_hybrid.png', vis)
    print(" -> debug_slots_hybrid.png ì €ì¥ë¨")

    return final_slots

# --- 5. TTA (ì¶”ë¡  ì‹œ ì¦ê°•) ---
def predict_with_tta(model, roi, class_names, tablet_classes, n_augmentations=5):
    predictions = []
    
    # [ìˆ˜ì • 3] ì „ì²˜ë¦¬ ë°©ì‹ ë³€ê²½ (NEAREST + preprocess_input)
    # ì›ë³¸ ì˜ˆì¸¡
    roi_rgb = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)
    
    # ë¦¬ì‚¬ì´ì¦ˆ: INTER_NEAREST (ë„íŠ¸ ìœ ì§€)
    roi_resized = cv2.resize(roi_rgb, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_NEAREST)
    
    # ì •ê·œí™”: preprocess_input (-1 ~ 1 ë²”ìœ„)
    roi_input = preprocess_input(roi_resized.astype(np.float32))[None, ...]
    
    pred_original = model.predict(roi_input, verbose=0)[0]
    predictions.append(pred_original)
    
    top_class = class_names[np.argmax(pred_original)]
    is_tablet = top_class in tablet_classes
    
    # ì¦ê°• ì˜ˆì¸¡ (TTA)
    if is_tablet:
        # ì„íŒ: 90ë„ì”© íšŒì „
        for angle in [90, 180, 270]:
            h, w = roi.shape[:2]
            M = cv2.getRotationMatrix2D((w/2, h/2), angle, 1)
            aug = cv2.warpAffine(roi, M, (w, h), borderMode=cv2.BORDER_REFLECT)

            # [ì¶”ê°€] ë°ê¸° ì¡°ì ˆ (ì„íŒë„ ì¡°ëª… íƒ€ë‹ˆê¹Œìš”!)
            brightness = np.random.randint(-20, 20)
            aug = np.clip(aug.astype(np.int16) + brightness, 0, 255).astype(np.uint8)

            aug_rgb = cv2.cvtColor(aug, cv2.COLOR_BGR2RGB)
            aug_resized = cv2.resize(aug_rgb, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_NEAREST)
            aug_input = preprocess_input(aug_resized.astype(np.float32))[None, ...]
            
            predictions.append(model.predict(aug_input, verbose=0)[0])
        tta_type = "Rotation"
    else:
        # ì¼ë°˜ ì•„ì´í…œ: ë¯¸ì„¸ íšŒì „ ë° ë°ê¸°
        for _ in range(n_augmentations - 1):
            aug = roi.copy()
            angle = np.random.uniform(-5, 5)
            h, w = aug.shape[:2]
            M = cv2.getRotationMatrix2D((w/2, h/2), angle, 1)
            aug = cv2.warpAffine(aug, M, (w, h), borderMode=cv2.BORDER_REFLECT)
            
            brightness = np.random.randint(-15, 15)
            aug = np.clip(aug.astype(np.int16) + brightness, 0, 255).astype(np.uint8)
            
            aug_rgb = cv2.cvtColor(aug, cv2.COLOR_BGR2RGB)
            aug_resized = cv2.resize(aug_rgb, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_NEAREST)
            aug_input = preprocess_input(aug_resized.astype(np.float32))[None, ...]
            
            predictions.append(model.predict(aug_input, verbose=0)[0])
        tta_type = "Small"
    
    return np.mean(predictions, axis=0), roi_resized, tta_type

# --- ë©”ì¸ ---
print("=" * 60)
model = load_model(MODEL_PATH)
with open(CLASSES_PATH, 'rb') as f:
    class_names = pickle.load(f)
tablet_classes = load_tablet_classes('./assets/tablets')
print("=" * 60)

frame = cv2.imread(SCREENSHOT_PATH)
if frame is None:
    print("âŒ ì´ë¯¸ì§€ ì—†ìŒ")
    exit()

print(f"\nì´ë¯¸ì§€: {frame.shape[1]}x{frame.shape[0]}")

# ìŠ¬ë¡¯ ìë™ ì°¾ê¸° (í•˜ì´ë¸Œë¦¬ë“œ)
slots = find_inventory_slots(frame)

if len(slots) == 0:
    print("âŒ ìŠ¬ë¡¯ ì—†ìŒ")
    print("ë””ë²„ê·¸: debug_mask_border.png í™•ì¸")
    exit()

print(f"\nâœ… {len(slots)}ê°œ ìŠ¬ë¡¯ ë°œê²¬")
print("debug_slots_hybrid.png í™•ì¸")

# ë¶„ì„ ë° ì‹œê°í™”
output_frame = frame.copy()

print("\n" + "=" * 60)
print("ë¶„ì„ ì¤‘...")
print("=" * 60)

for idx, (x, y, w, h) in enumerate(slots):
    roi = frame[y:y+h, x:x+w]
    if roi.size == 0:
        continue
    
    cv2.imwrite(f'./CNN/debug_test_rois/slot_{idx}.png', roi)
    
    try:
        prediction, roi_final, tta_type = predict_with_tta(model, roi, class_names, tablet_classes)
        cv2.imwrite(f'./CNN/debug_test_processed/slot_{idx}_final.png', 
                    cv2.cvtColor(roi_final, cv2.COLOR_RGB2BGR))
    except Exception as e:
        print(f"[{idx}] âŒ ì˜¤ë¥˜: {e}")
        continue
    
    # ê²°ê³¼ ì²˜ë¦¬
    pred_idx = np.argmax(prediction)
    confidence = prediction[pred_idx]
    label = class_names[pred_idx]

    top3 = np.argsort(prediction)[-3:][::-1]
    print(f"[{idx}] {label} ({confidence*100:.0f}%) [{tta_type}]")
    
    # ì‹œê°í™”
    color = (0, 255, 0) if confidence > 0.5 else (0, 0, 255)
    cv2.rectangle(output_frame, (x, y), (x+w, y+h), color, 2)
    
    # í…ìŠ¤íŠ¸ ë°°ê²½ (ê°€ë…ì„±)
    cv2.rectangle(output_frame, (x, y-20), (x+100, y), (0, 0, 0), -1)
    cv2.putText(output_frame, label[:12], (x+2, y-5), 
                cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)

cv2.imwrite('./CNN/inventory_result.png', output_frame)
print("\nâœ… ë¶„ì„ ì™„ë£Œ! inventory_result.png ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

cv2.imshow('Result', output_frame)
cv2.waitKey(0)
cv2.destroyAllWindows()